{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch, sys\n",
    "from torchvision.transforms import functional as func\n",
    "import torchvision.transforms as transforms\n",
    "from loss import ComputeLoss\n",
    "import yaml, random\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "from fiftyone import ViewField as F\n",
    "from new_model import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.ticker import NullLocator\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataloader import FiftyOneTorchDataset, collate_fn\n",
    "from util import non_max_suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training set using our changed 51 dataloader.\n",
    "dataset_train = foz.load_zoo_dataset(\n",
    "    \"coco-2017\", # Specify which COCO dataset to use. \n",
    "    split=\"train\", # Specify training, validation, or test dataset from COCO.\n",
    "    classes=[\"cat\", \"dog\", \"horse\", \"giraffe\"], # Specify the classes\n",
    "    max_samples=256, # Specify number of samples.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the validation set.\n",
    "dataset_validation = foz.load_zoo_dataset(\n",
    "    \"coco-2017\",\n",
    "    split=\"validation\",\n",
    "    classes=[\"cat\", \"dog\", \"horse\", \"giraffe\"],\n",
    "    max_samples=64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the dataset to be used in training.\n",
    "dataset_train.persistent = True\n",
    "dataset_validation.persistent = True\n",
    "view_train = dataset_train.filter_labels(\"ground_truth\", F(\"label\").is_in((\"cat\", \"dog\", \"horse\", \"giraffe\")))\n",
    "view_val = dataset_validation.filter_labels(\"ground_truth\", F(\"label\").is_in((\"cat\", \"dog\", \"horse\", \"giraffe\")))\n",
    "\n",
    "# Filter out the classes.\n",
    "fil_classes = [\"cat\", \"dog\", \"horse\", \"giraffe\"]\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "# Try opening our configuration file.\n",
    "with open(\"hyp.yaml\", \"r\") as stream:\n",
    "    try:\n",
    "        hyp = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "# Resize the image.\n",
    "org_w = 640\n",
    "org_h = 480\n",
    "scaling_factor = 640/480\n",
    "\n",
    "# Batch size.\n",
    "batch_size = 8\n",
    "\n",
    "# Add zero padding to image to make it a square image.\n",
    "transform = transforms.Compose([transforms.Resize((int(org_h/scaling_factor), int(org_w/scaling_factor))),\n",
    "                                transforms.Pad((0, int((org_w - org_h)/(2*scaling_factor)),0,int((org_w - org_h)/(2*scaling_factor)))),\n",
    "                                transforms.ToTensor()])\n",
    "\n",
    "# Load the data loaders for training and validation.\n",
    "dataset_train = FiftyOneTorchDataset(view_train, transform, classes=fil_classes)\n",
    "dataset_val = FiftyOneTorchDataset(view_val, transform, classes=fil_classes)\n",
    "loader_train = DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True)\n",
    "loader_val = DataLoader(dataset=dataset_val, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the collate function for the dataloader.\n",
    "loader_train = DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "loader_val = DataLoader(dataset=dataset_val, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load the model and set up the optimizer and the custom loss function.\n",
    "model = Model('yolov3.yaml', hyp=hyp).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),1e-3)\n",
    "loss_fcn = ComputeLoss(model)\n",
    "\n",
    "# Keeps track of results.\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "epochs = 10\n",
    "#epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # Train the model in batches.\n",
    "    tot_loss = 0\n",
    "    count = 0\n",
    "    for images, targets in loader_train:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        preds = model(images)\n",
    "        loss, loss_parts = loss_fcn(preds, targets)\n",
    "        tot_loss += loss / batch_size\n",
    "        count += 1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Save the model each 50 epochs\n",
    "    if epoch%10==0 and epoch!=0:\n",
    "        torch.save(model,'./models/model'+str(epoch)+'.pt')\n",
    "    print(epoch, 'Training:\\t',epoch, tot_loss.item()/count)\n",
    "    train_loss_list.append(tot_loss.item()/count)\n",
    "    \n",
    "    # For validationâ‰¥\n",
    "    tot_loss = 0\n",
    "    count = 0\n",
    "    for images, targets in loader_val:\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        with torch.no_grad():\n",
    "            preds = model(images)\n",
    "            loss, loss_parts = loss_fcn(preds, targets)\n",
    "            tot_loss += loss / batch_size\n",
    "        count += 1\n",
    "    print('\\tValidation:\\t', tot_loss.item()/count)\n",
    "    val_loss_list.append(tot_loss.item()/count)\n",
    "    \n",
    "\n",
    "# Save the final model and the list results.\n",
    "torch.save(model,'./models/final'+'.pt')    \n",
    "\n",
    "from util import my_load,my_save\n",
    "my_save('trainloss',train_loss_list)\n",
    "my_save('validationloss',val_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results.\n",
    "from util import plot\n",
    "plot(train_loss_list,val_loss_list,'train loss','val loss','loss','train loss and validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the saved model.\n",
    "from util import my_img_plot\n",
    "import gc\n",
    "gc.collect() \n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda:0')\n",
    "model = torch.load('./models/final.pt').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate prediction images for visualization.\n",
    "model.eval()\n",
    "for images, targets in loader_train:\n",
    "    # for image in images:\n",
    "    images = images.to(device)\n",
    "    with torch.no_grad():\n",
    "        pred = model(images)\n",
    "        my_img_plot(pred[0],images[0],fil_classes,1)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65768f95ed3f1ad80799466926a66640b39a99ef5d94bbece814e59aa067606e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
